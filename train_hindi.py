"""
train_hindi.py โ Hindi training pipeline with 4-class disease merge
Maps all 29 Hindi diseases โ 4 canonical groups matching the English model.

FINAL 4 CLASSES (same as English train.py)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
  1. Avascular Necrosis    โ AVN variants, arthritic hip, BMES, DDH, infected hip, TB hip
  2. Osteoarthritis        โ OA + RA (indistinguishable by symptoms)
  3. Hip & Bone Fracture   โ all fracture variants
  4. Other Orthopaedic     โ spinal tumors, discharge destination

RUN
โโโ
  python train_hindi.py
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import xgboost as xgb
import joblib
import os
import json
import warnings
warnings.filterwarnings("ignore")

# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# PATHS
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
DATA_PATH = "data/updated_result_with_AI_HINDI.csv"
MODEL_DIR = "model/hindi"
os.makedirs(MODEL_DIR, exist_ok=True)

# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# DISEASE MERGE MAP โ All 29 Hindi labels โ 4 canonical classes
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

# โโ GROUP 1: AVASCULAR NECROSIS โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# All AVN variants + conditions with same hip pain/mobility/stiffness profile
AVASCULAR_NECROSIS_HI = [
    "เคเฅเคฒเฅเคนเฅ เคเคพ เคเคตเคพเคธเฅเคเฅเคฒเคฐ เคจเฅเคเฅเคฐเฅเคธเคฟเคธ",
    "เคฆเฅเคจเฅเค เคเฅเคฒเฅเคนเฅ เคเคพ เคเคธเฅเคตเคพเคธเฅเคเฅเคฒเคฐ เคจเฅเคเฅเคฐเฅเคธเคฟเคธ",
    "เคฌเคพเคเค เคเฅเคฒเฅเคนเฅ เคเคพ เคเคธเฅเคตเคพเคธเฅเคเฅเคฒเคฐ เคจเฅเคเฅเคฐเฅเคธเคฟเคธ",
    "เคฆเคพเคนเคฟเคจเฅ เคเฅเคฒเฅเคนเฅ เคเคพ เคเคธเฅเคตเคพเคธเฅเคเฅเคฒเคฐ เคจเฅเคเฅเคฐเฅเคธเคฟเคธ",
    "เคฐเคเฅเคค เคธเคเคเคพเคฐ เคฐเฅเคเคจเฅ เคธเฅ เคนเคกเฅเคกเฅ เคเคพ เคเคฒเคจเคพ",        # standalone AVN
    "เคเคฐเฅเคฅเฅเคฐเคพเคเคเคฟเค เคเฅเคฒเฅเคนเฅ",                        # arthritic hip
    "เคเคฐเฅเคฅเฅเคฐเคพเคเคเคฟเค เคเฅเคฒเฅเคนเฅ (เคเคธเคฟเคเฅเคฌเฅเคฒเคฐ เคซเฅเคฐเฅเคเฅเคเคฐ)",
    "เคฆเคพเคนเคฟเคจเฅ เคเฅเคฒเฅเคนเฅ เคเคพ เคฌเฅเคจ เคฎเฅเคฐเฅ เคเคกเคฟเคฎเคพ เคธเคฟเคเคกเฅเคฐเฅเคฎ",  # BMES right
    "เคฌเคพเคฏเฅเค เคเฅเคฒเฅเคนเฅ เคเคพ เคฌเฅเคจ เคฎเฅเคฐเฅ เคเคกเคฟเคฎเคพ เคธเคฟเคเคกเฅเคฐเฅเคฎ",   # BMES left
    "เคฆเฅเคจเฅเค เคเฅเคฒเฅเคนเฅเฅเคธ เคเคพ เคฌเฅเคจ เคฎเฅเคฐเฅ เคเคกเคฟเคฎเคพ เคธเคฟเคเคกเฅเคฐเฅเคฎ", # BMES bilateral
    "เคเฅเคฐเฅเคฎเคพ เคเฅ เคฌเคพเคฆ เคกเคพเคฏเคจเฅเคฎเคฟเค เคเฅเคฒเฅเคนเฅ เคธเฅเคเฅเคฐเฅ",       # Dynamic Hip Screw
    "เคเฅเคฒเฅเคนเฅ เคเคพ เคคเคชเฅเคฆเคฟเค",                            # TB hip
    "เคธเคเคเฅเคฐเคฎเคฟเคค เคเฅเคฒเฅเคนเฅ",                             # infected hip
    "เคชเฅเคธเฅเค-เคเฅเคฐเฅเคฎเฅเคเคฟเค เคเฅเคฒเฅเคนเฅ เคเคเคเคฐเฅ",               # post-traumatic hip
    "เคเฅเคฒเฅเคนเฅ เคเคพ เคตเคฟเคเคพเคธเคพเคคเฅเคฎเค เคเคธเคพเคฎเคพเคจเฅเคฏเคคเคพ",             # DDH
]

# โโ GROUP 2: OSTEOARTHRITIS โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# OA + RA share indistinguishable symptom profiles (sim=0.996)
OSTEOARTHRITIS_HI = [
    " เคเคธเฅเคเคฟเคฏเฅเคเคฐเฅเคฅเคฐเคพเคเคเคฟเคธ",           # note: leading space matches raw PKL output
    "เคเคธเฅเคเคฟเคฏเฅเคเคฐเฅเคฅเคฐเคพเคเคเคฟเคธ",             # without leading space (safety net)
    "เคเคธเฅเคเคฟเคฏเฅเคเคเคฟเคฏเคพ เคเคพ เคจเคฟเคฆเคพเคจ เคเคเฅเคธ-เคฐเฅ เคธเฅ",
    "เคเคเคฟเคฏเคพ",                          # Arthritis
    "เคฐเฅเคฎเฅเคเฅเคฏเคก เคเคเคฟเคฏเคพ",                 # Rheumatoid Arthritis
]

# โโ GROUP 3: HIP & BONE FRACTURE โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
HIP_BONE_FRACTURE_HI = [
    "เคเคธเคฟเคเฅเคฌเฅเคฒเคฐ เคซเฅเคฐเฅเคเฅเคเคฐ",
    "เคเคธเคฟเคเฅเคฌเฅเคฒเคฐ เคซเฅเคฐเฅเคเฅเคเคฐ / เคซเฅเคฎเคฐ เคซเฅเคฐเฅเคเฅเคเคฐ",
    "เคจเคเคผเคฐเคเคเคฆเคพเคเคผ เคเคฟเคฏเคพ เคเคฏเคพ เคเคธเคฟเคเฅเคฌเฅเคฒเคฐ เคซเฅเคฐเฅเคเฅเคเคฐ",
    "เคซเฅเคฎเคฐ เคเฅ เคเคฐเฅเคฆเคจ เคเคพ เคซเฅเคฐเฅเคเฅเคเคฐ",
    "เคซเฅเคฎเคฐ เคเฅ เคเคฐเฅเคฆเคจ เคเคพ เคซเฅเคฐเฅเคเฅเคเคฐ + เคถเคพเคซเฅเค เคจเฅเคจ-เคฏเฅเคจเคฟเคฏเคจ",
    "neglected เคซเฅเคฎเคฐ เคเฅ เคเคฐเฅเคฆเคจ เคเคพ เคซเฅเคฐเฅเคเฅเคเคฐ",
    "เคเฅเคฐเฅเคเฅเคเคเคฐ เคซเฅเคฐเฅเคเฅเคเคฐ",
    "failed เคเฅเคฐเฅเคเฅเคเคเคฐ เคซเฅเคฐเฅเคเฅเคเคฐ",
]

# โโ GROUP 4: OTHER ORTHOPAEDIC โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# Spinal + discharge outcomes โ everything unmapped also falls here
OTHER_ORTHOPAEDIC_HI = [
    "เคฐเฅเคขเคผ เคเฅ เคนเคกเฅเคกเฅ เคเฅ เคเฅเคฏเฅเคฎเคฐ",
    "เคธเคฐเฅเคเคฐเฅ เคเฅ เคฌเคพเคฆ เคกเคฟเคธเฅเคเคพเคฐเฅเค เคเคเคคเคตเฅเคฏ",
]

# Build merge dict
DISEASE_MERGE_HI = {}
for d in AVASCULAR_NECROSIS_HI:
    DISEASE_MERGE_HI[d] = "Avascular Necrosis"
for d in OSTEOARTHRITIS_HI:
    DISEASE_MERGE_HI[d] = "Osteoarthritis"
for d in HIP_BONE_FRACTURE_HI:
    DISEASE_MERGE_HI[d] = "Hip & Bone Fracture"
for d in OTHER_ORTHOPAEDIC_HI:
    DISEASE_MERGE_HI[d] = "Other Orthopaedic"

# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# STEP 1 โ LOAD DATASET
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
print("๐ Loading Hindi medical dataset...")
df = pd.read_csv(DATA_PATH)

df = df[['Pseudonymized_Diagnosis', 'Pseudonymized_symptoms']].copy()
df.columns = ['Disease', 'symptoms']
df = df.dropna()
df['Disease']  = df['Disease'].str.strip()
df['symptoms'] = df['symptoms'].str.strip().str.lower()

print(f"   Raw rows: {len(df)} | Raw diseases: {df['Disease'].nunique()}")

# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# STEP 2 โ APPLY MERGE MAP
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
print("\n๐ Applying disease merge map...")

# Any label not explicitly mapped โ "Other Orthopaedic"
df['Disease'] = df['Disease'].map(DISEASE_MERGE_HI).fillna("Other Orthopaedic")

print(f"   After merge: {len(df)} rows | {df['Disease'].nunique()} canonical classes")
print(f"   Zero rows dropped โ all {len(df)} rows used\n")
print("   Class distribution:")
for disease, count in df['Disease'].value_counts().items():
    bar = 'โ' * (count // 5)
    print(f"     {count:5d}  {disease:<25} {bar}")

# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# STEP 3 โ BUILD SYMPTOM MATRIX
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
print("\n๐ง Building symptom matrix...")

symptom_lists = df['symptoms'].str.split(',').apply(
    lambda x: [s.strip() for s in x if s.strip()]
)
all_symptoms = sorted(set(s for sublist in symptom_lists for s in sublist))
print(f"   Unique symptoms: {len(all_symptoms)}")

X = pd.DataFrame(0, index=df.index, columns=all_symptoms)
for i, symptoms in zip(df.index, symptom_lists):
    X.loc[i, symptoms] = 1

y = df['Disease']
print(f"   Matrix shape: {X.shape}")

# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# STEP 4 โ ENCODE LABELS
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
le        = LabelEncoder()
y_encoded = le.fit_transform(y)

# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# STEP 5 โ SAVE ARTIFACTS
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
symptom_list = X.columns.tolist()
disease_list = le.classes_.tolist()

joblib.dump(symptom_list, f"{MODEL_DIR}/symptom_list.pkl")
joblib.dump(le,           f"{MODEL_DIR}/label_encoder.pkl")

with open(f"{MODEL_DIR}/symptom_list.json", "w", encoding="utf-8") as f:
    json.dump(symptom_list, f, indent=2, ensure_ascii=False)
with open(f"{MODEL_DIR}/disease_list.json", "w", encoding="utf-8") as f:
    json.dump(disease_list, f, indent=2, ensure_ascii=False)

print(f"   โ Saved {len(symptom_list)} symptoms, {len(disease_list)} diseases")
print(f"   disease_list.json: {disease_list}")

# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# STEP 6 โ TRAIN / TEST SPLIT
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)
print(f"\n๐ Train: {len(X_train)} | Test: {len(X_test)}")

# Convert to numpy for XGBoost compatibility
X_train_np = X_train.values
X_test_np  = X_test.values

# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# STEP 7 โ TRAIN MODELS
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
print("\n๐๏ธ  Training models...\n")

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

models = {
    "Random Forest": RandomForestClassifier(
        n_estimators=200,
        max_depth=20,
        class_weight="balanced",
        random_state=42,
        n_jobs=-1
    ),
    "XGBoost": xgb.XGBClassifier(
        n_estimators=150,
        learning_rate=0.1,
        max_depth=6,
        eval_metric="mlogloss",
        random_state=42,
        n_jobs=-1,
        verbosity=0
    ),
    "Gradient Boosting": HistGradientBoostingClassifier(
        max_iter=200,
        learning_rate=0.05,
        max_depth=6,
        random_state=42
    ),
}

results       = {}
trained_models = {}

for name, model in models.items():
    print(f"   Training {name}...")
    cv_scores = cross_val_score(
        model, X_train_np, y_train, cv=cv, scoring="accuracy", n_jobs=-1
    )
    model.fit(X_train_np, y_train)
    test_acc = accuracy_score(y_test, model.predict(X_test_np))

    results[name] = {
        "cv_mean":     round(float(cv_scores.mean()), 4),
        "cv_std":      round(float(cv_scores.std()), 4),
        "test_acc":    round(float(test_acc), 4),
        "fold_scores": cv_scores.tolist(),
    }
    trained_models[name] = model
    print(f"   {name}: CV={cv_scores.mean():.4f} ยฑ {cv_scores.std():.4f} | Test={test_acc:.4f}")

# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# STEP 8 โ SELECT & SAVE BEST MODEL
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
best_name  = max(results, key=lambda k: results[k]["cv_mean"])
best_model = trained_models[best_name]
print(f"\nโ Best model: {best_name}")

joblib.dump(best_model, f"{MODEL_DIR}/best_model.pkl")

y_pred = best_model.predict(X_test_np)
cm     = confusion_matrix(y_test, y_pred)
np.save(f"{MODEL_DIR}/confusion_matrix.npy", cm)

report = classification_report(
    y_test, y_pred,
    target_names=le.classes_,
    zero_division=0,
    output_dict=True
)

metadata = {
    "language":      "Hindi",
    "best_model":    best_name,
    "results":       results,
    "n_symptoms":    len(symptom_list),
    "n_diseases":    len(disease_list),
    "train_size":    len(X_train),
    "test_size":     len(X_test),
    "data_source":   "Hindi dataset โ 4 merged classes, all rows used",
    "class_report":  report,
    "cv_mean":       results[best_name]["cv_mean"],
    "cv_std":        results[best_name]["cv_std"],
    "test_accuracy": results[best_name]["test_acc"],
}

with open(f"{MODEL_DIR}/metadata.json", "w", encoding="utf-8") as f:
    json.dump(metadata, f, indent=2, ensure_ascii=False)

# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# STEP 9 โ FINAL REPORT
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
print("\n๐ Classification Report:")
print(classification_report(y_test, y_pred, target_names=le.classes_, zero_division=0))
print("โ Done. Hindi artifacts saved in /model/hindi")
print(f"   disease_list.json: {disease_list}")