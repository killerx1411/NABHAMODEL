# NABHAMODEL
Hereâ€™s a **professional and complete README** you can use for your GitHub repo **[README for NABHAMODEL](https://github.com/killerx1411/NABHAMODEL)** (multilingual disease prediction system):

---

# NABHAMODEL

**Multilingual Disease Prediction System** â€“ A FastAPI-based API that predicts diseases from symptom text in **English, Hindi, and Punjabi** using native language models.

This project includes training scripts, language detection, and a ready API to serve predictions in multiple languages.

---

## ğŸš€ Features

âœ… Predict diseases from free-text symptoms
âœ… Works with **English, Hindi & Punjabi**
âœ… Automatic language detection
âœ… Modular training and validation scripts
âœ… Model storage with language-specific folders
âœ… Docker support

---

## ğŸ› ï¸ Project Structure

```text
.
â”œâ”€â”€ app/                       
â”œâ”€â”€ data/                      # Place your datasets here
â”œâ”€â”€ model/                     # Trained models saved here
â”œâ”€â”€ train.py                   # Train English model
â”œâ”€â”€ train_hindi.py             # Train Hindi model
â”œâ”€â”€ train_punjabi.py           # Train Punjabi model
â”œâ”€â”€ validate.py                # Validation/testing script
â”œâ”€â”€ main_multilingual.py       # API entrypoint
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ MULTILINGUAL_SETUP.md      # Setup guide
```

---

## ğŸ“¦ Prerequisites

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸ“¥ Data Preparation

Put the dataset CSV files under **data/**:

```
data/
â”œâ”€â”€ dataset.csv                  # English dataset
â”œâ”€â”€ updated_result_with_AI_HINDI.csv
â””â”€â”€ updated_result_with_AI_PUNJABI.csv
```

---

## ğŸ‹ï¸â€â™‚ï¸ Training Models

Train each language model:

English:

```bash
python train.py
```

Hindi:

```bash
python train_hindi.py
```

Punjabi:

```bash
python train_punjabi.py
```

Models will be saved under **model/**:

```
model/
â”œâ”€â”€ best_model.pkl  
â”œâ”€â”€ label_encoder.pkl
â”œâ”€â”€ symptom_list.pkl
â”œâ”€â”€ hindi/
â””â”€â”€ punjabi/
```

---

## ğŸš€ Running the API

Start the API with automatic language detection:

```bash
uvicorn app.main:app --reload
```

Or rename entrypoint:

```bash
mv app/main_multilingual.py app/main.py
uvicorn app.main:app --reload
```

Access API docs:

```
http://localhost:8000/docs
```

---

## ğŸ§ª Sample API Usage

#### English Prediction

```bash
curl -X POST http://localhost:8000/predict \
 -H "Content-Type: application/json" \
 -d '{"text":"I have fever, cough and headache"}'
```

#### Hindi Prediction

```bash
curl -X POST http://localhost:8000/predict \
 -H "Content-Type: application/json" \
 -d '{"text":"à¤®à¥à¤à¥‡ à¤¬à¥à¤–à¤¾à¤°, à¤–à¤¾à¤‚à¤¸à¥€ à¤”à¤° à¤¸à¤¿à¤°à¤¦à¤°à¥à¤¦ à¤¹à¥ˆ"}'
```

#### Punjabi Prediction

```bash
curl -X POST http://localhost:8000/predict \
 -H "Content-Type: application/json" \
 -d '{"text":"à¨®à©ˆà¨¨à©‚à©° à¨¬à©à¨–à¨¾à¨°, à¨–à©°à¨˜ à¨…à¨¤à©‡ à¨¸à¨¿à¨°à¨¦à¨°à¨¦ à¨¹à©ˆ"}'
```

---

## ğŸ“¡ API Endpoints

| Endpoint   | Method | Description                       |
| ---------- | ------ | --------------------------------- |
| `/`        | GET    | API info & supported languages    |
| `/models`  | GET    | List loaded models                |
| `/predict` | POST   | Multi-language disease prediction |
| `/docs`    | GET    | Interactive API docs              |

---

## ğŸ§  How It Works

1. API receives symptom text
2. `langdetect` detects language
3. Routes to appropriate model (English/Hindi/Punjabi)
4. Returns prediction in same language

---

## ğŸ§ª Testing

Run the validation script after training:

```bash
python validate.py
```

---

## ğŸ³ Docker (Optional)

Build Docker image:

```bash
docker build -t nabhamodel .
```

Run container:

```bash
docker run -p 8000:8000 nabhamodel
```

---

## ğŸ“Œ Notes

âœ” Hindi & Punjabi models are trained on **native language medical datasets**, not via translation.
âœ” Automatic language detection means users need not specify language manually.

---

## ğŸ™Œ Contributions

Got ideas or improvements?
Feel free to open issues or pull requests.

---

If you want, I can also provide a **Markdown badge section** (build, coverage, license) to polish it further.
